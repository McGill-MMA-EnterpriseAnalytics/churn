# -*- coding: utf-8 -*-
"""02_Churn-Prediction-Python-Notebook-With-All-Predictors

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WB1mFlygj6zE0gGsgqBCPEa3HAX78u5z

Importing the required Libraries
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import (
    StandardScaler,
    LabelEncoder
)
from sklearn.metrics import (
    auc,
    roc_auc_score,
    roc_curve,
    accuracy_score,
    precision_score,
    average_precision_score,
    recall_score,
    f1_score,
    precision_recall_curve,
    confusion_matrix
)
from sklearn.model_selection import (
    train_test_split,
    StratifiedKFold,
    cross_val_score,
)
import seaborn as sns
from sklearn import (
    ensemble,
    model_selection,
    preprocessing,
    tree
)

"""Importing the data"""

from google.colab import files
uploaded = files.upload()

"""Reading the data"""

df = pd.read_csv("01_Dataset.csv")
df.head(10)

"""Checking the data types of features"""

df.dtypes

df.dtypes.value_counts().sort_values().plot(kind='barh',
                                            figsize=(22, 6),
                                            fontsize=16)

plt.title('Number of columns by data types', fontsize=18)
plt.xlabel('Number of columns', fontsize=16)
plt.ylabel('Data type', fontsize=16)

"""####A lot of Categorical variables, let's look how many outcomes are possible for each categorical variable"""

nunique_df = pd.DataFrame(df.select_dtypes('object').apply(pd.Series.nunique, axis=0), columns=['Variants'])
nunique_df = nunique_df.reset_index()
nunique_df.columns = ['Column Name', 'Variants']
nunique_df

"""The data type for TotalCharges is Object, this should be typecasted to float. The missing values are replaced by 0"""

for i in range(len(df)):
    if df.TotalCharges.iloc[i] != ' ':
         df.TotalCharges.iloc[i] = float(df.TotalCharges.iloc[i])
    else:
        df.TotalCharges.iloc[i] = 0

df = df.astype({'TotalCharges': 'float'})

df.describe()

"""Checking for missing values in columns other than TotalCharges since that column is already dealt with"""

def missing_values(df):
    mis_val = df.isnull().sum()
    mis_val_percent = 100 * df.isnull().sum() / len(df)
    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
    mis_val_table_ren_columns = mis_val_table.rename(columns={
        0: 'Missing Values',
        1: '% of Total Values'
    })
    mis_val_table_ren_columns = mis_val_table_ren_columns[
        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(
            '% of Total Values', ascending=False).round(1)
    print("Dataframe has " + str(df.shape[1]) + " columns.")
    print("There are " + str(mis_val_table_ren_columns.shape[0]) +
          " columns that have missing values.")
    
    return mis_val_table_ren_columns

# Missing values statistics
miss_values = missing_values(df)
miss_values.head(20)

"""No missing Value

Creating a target variable
"""

df['Churn'].unique()

target = [ 1 if i == 'Yes' else 0 for i in df['Churn']]

df['target'] = target
df['target'].value_counts()

"""We notice that 0 is much more common of an outcome than 1"""

df.drop('Churn', axis=1, inplace=True)

"""Checking correlation between numerical variables"""

corr = df.corr()['target'].sort_values()

# Display correlations
print('Top 5 - Positive Correlations:')
print('-----------------------------------')
print(corr.tail(5))
print('\nTop 5 - Negative Correlations:')
print('------------------------------')
print(corr.head(5))

"""####Visualising the Correaltion"""

correlation = df.corr()
plt.figure(figsize=(16, 16))
ax = sns.heatmap(
    correlation, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
)

"""Dropping ID column"""

df.drop(['customerID'],
        axis=1,
        inplace=True)

df.head(5)

"""#### Encoding and Dummifying"""

class MultiColumnLabelEncoder:
    def __init__(self,columns = None):
        self.columns = columns # array of column names to encode

    def fit(self,X,y=None):
        return self # not relevant here

    def transform(self,X):
        '''
        Transforms columns of X specified in self.columns using
        LabelEncoder(). If no columns specified, transforms all
        columns in X.
        '''
        output = X.copy()
        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname,col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)
        return output

    def fit_transform(self,X,y=None):
        return self.fit(X,y).transform(X)

df.columns

binary = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']
df = MultiColumnLabelEncoder(columns = binary).fit_transform(df)
df.head()

categorical = ['MultipleLines', 'InternetService', 'OnlineSecurity',
       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',
       'StreamingMovies', 'Contract', 'PaymentMethod']
df = pd.get_dummies(df, columns = categorical)

df.head()

df.columns

"""Making feature vectors and target variable"""

y = df.target
X = df.drop(['target'], axis = 1)

X.shape

df.to_excel('no_removal_preprocessed_data.xlsx')

"""##  Trying different models"""

results = {
    'Model':[], 
    'Accuracy':[], 
    'F1 Score':[]
    }

"""####  1. K-NN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
standardizer = StandardScaler()

X_std = standardizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size = 0.33, random_state = 7)

knn = KNeighborsClassifier(n_neighbors = 7)
model = knn.fit(X_train, y_train)


y_test_pred = knn.predict(X_test)

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_test_pred)
print(acc, f1_score(y_test, y_test_pred))

results['Model'].append('KNN')
results['Accuracy'].append(acc)
results['F1 Score'].append(f1_score(y_test, y_test_pred))

"""#### 2. Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size = 0.33, random_state = 5)

dtree = DecisionTreeClassifier(max_depth = 5)
model = dtree.fit(X_train, y_train)

y_test_pred = dtree.predict(X_test)

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_test_pred)

print(acc, f1_score(y_test, y_test_pred))

results['Model'].append('DecisionTree')
results['Accuracy'].append(acc)
results['F1 Score'].append(f1_score(y_test, y_test_pred))

"""####  3. Random Forest"""

from sklearn.ensemble import RandomForestClassifier
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 5)

rf = RandomForestClassifier(random_state = 0, n_estimators = 1000)
model = rf.fit(X_train, y_train)

y_test_pred = rf.predict(X_test)

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_test_pred)

print(acc, f1_score(y_test, y_test_pred))

results['Model'].append('Random Forest')
results['Accuracy'].append(acc)
results['F1 Score'].append(f1_score(y_test, y_test_pred))

results

from sklearn.model_selection import GridSearchCV
 import numpy as np
 
 

base_model = RandomForestClassifier(n_estimators = 100, random_state = 0)
base_model.fit(X_train, y_train)
base_acc = accuracy_score(y_test, base_model.predict(X_test))

# Create the parameter grid based on the results of random search 
param_grid = {
    'bootstrap': [True],
    'max_depth': [80, 90, 100, 110],
    'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 200, 300, 500, 700, 1000]
}
# Create a based model
rf = RandomForestClassifier()
# Instantiate the grid search model
grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          cv = 3, n_jobs = -1, verbose = 2)
# Fit the grid search to the data
grid_search.fit(X, y)
grid_search.best_params_

best_grid = grid_search.best_estimator_
grid_acc = accuracy_score(y_test, best_grid.predict(X_test))
 
print('Improvement of {:0.2f}%.'.format( 100 * (grid_acc - base_acc) / base_acc))


print(grid_acc, f1_score(y_test, y_test_pred))

results['Model'].append('Tuned Random Forest')
results['Accuracy'].append(grid_acc)
results['F1 Score'].append(f1_score(y_test,best_grid.predict(X_test)))

"""#### 4. Logistic Regression"""

from sklearn.linear_model import LogisticRegression
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 5)

lm3 = LogisticRegression()
model3 = lm3.fit(X_train, y_train)

y_test_pred = lm3.predict(X_test)

acc = accuracy_score(y_test,y_test_pred)

print(acc, f1_score(y_test, y_test_pred))

results['Model'].append('Logistic Regression')
results['Accuracy'].append(acc)
results['F1 Score'].append(f1_score(y_test, y_test_pred))

"""#### 5. XG Boost Classifier

#### Grid Search CV to tune Random Forest Classifier
"""

import xgboost as xgb

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state = 5)

xgc = xgb.XGBClassifier()

xgc.fit(X_train,y_train)

preds = xgc.predict(X_test)

acc = (accuracy_score(y_test, preds))

print(acc, f1_score(y_test, preds))

results['Model'].append('XG Boost')
results['Accuracy'].append(acc)
results['F1 Score'].append(f1_score(y_test, preds))

"""####Results"""

results_df = pd.DataFrame(results)
results_df.to_excel('results without dropping any predictor.xlsx')
results_df